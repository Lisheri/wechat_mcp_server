#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®ç®¡ç†å™¨
è´Ÿè´£æ•°æ®æ”¶é›†ã€å­˜å‚¨å’ŒæŠ¥å‘Šç”Ÿæˆ
"""

import json
import os
import time
from datetime import datetime
from config import CrawlerConfig

class DataManager:
    """æ•°æ®ç®¡ç†å™¨"""
    
    def __init__(self):
        self.crawl_data = {
            "crawl_info": {
                "start_time": datetime.now().isoformat(),
                "app_name": "",
                "total_pages": 0,
                "total_buttons": 0,
                "crawl_duration": 0
            },
            "pages": [],
            "navigation_map": {},
            "feature_summary": {}
        }
        self.visited_buttons = set()
        self.start_time = time.time()
    
    def set_app_name(self, app_name):
        """è®¾ç½®åº”ç”¨åç§°"""
        self.crawl_data['crawl_info']['app_name'] = app_name
    
    def add_page_data(self, page_data):
        """æ·»åŠ é¡µé¢æ•°æ®"""
        self.crawl_data['pages'].append(page_data)
    
    def add_navigation_mapping(self, button_text, page_name):
        """æ·»åŠ å¯¼èˆªæ˜ å°„"""
        self.crawl_data['navigation_map'][button_text] = page_name
    
    def add_visited_button(self, button_id):
        """æ·»åŠ å·²è®¿é—®çš„æŒ‰é’®"""
        self.visited_buttons.add(button_id)
    
    def is_button_visited(self, button_id):
        """æ£€æŸ¥æŒ‰é’®æ˜¯å¦å·²è®¿é—®"""
        return button_id in self.visited_buttons
    
    def finalize_crawl_data(self):
        """å®Œæˆçˆ¬å–æ•°æ®çš„æœ€ç»ˆå¤„ç†"""
        end_time = time.time()
        self.crawl_data['crawl_info']['end_time'] = datetime.now().isoformat()
        self.crawl_data['crawl_info']['crawl_duration'] = round(end_time - self.start_time, 2)
        self.crawl_data['crawl_info']['total_pages'] = len(self.crawl_data['pages'])
        self.crawl_data['crawl_info']['total_buttons'] = len(self.visited_buttons)
        
        # ç”ŸæˆåŠŸèƒ½æ€»ç»“
        self._generate_feature_summary()
    
    def _generate_feature_summary(self):
        """ç”ŸæˆåŠŸèƒ½æ€»ç»“"""
        summary = {
            'total_unique_features': set(),
            'feature_categories': {},
            'page_types': {},
            'navigation_depth': 0,
            'color_themes': [],
            'layout_patterns': []
        }
        
        for page in self.crawl_data['pages']:
            features = page.get('extracted_features', {})
            
            # æ”¶é›†åŠŸèƒ½ç±»å‹
            for func in features.get('functionality', []):
                func_type = func.get('type', '')
                if func_type:
                    summary['total_unique_features'].add(func_type)
                    if func_type not in summary['feature_categories']:
                        summary['feature_categories'][func_type] = 0
                    summary['feature_categories'][func_type] += 1
            
            # åˆ†æé¡µé¢ç±»å‹
            page_name = page.get('page_name', '')
            page_type = self._classify_page_type(page_name)
            
            if page_type not in summary['page_types']:
                summary['page_types'][page_type] = 0
            summary['page_types'][page_type] += 1
            
            # æ”¶é›†é¢œè‰²ä¸»é¢˜
            colors = features.get('colors', [])
            if colors:
                primary_color = colors[0].get('color', '')
                if primary_color and primary_color not in summary['color_themes']:
                    summary['color_themes'].append(primary_color)
        
        # è½¬æ¢setä¸ºlistä»¥ä¾¿JSONåºåˆ—åŒ–
        summary['total_unique_features'] = list(summary['total_unique_features'])
        summary['feature_count'] = len(summary['total_unique_features'])
        
        self.crawl_data['feature_summary'] = summary
    
    def _classify_page_type(self, page_name):
        """åˆ†ç±»é¡µé¢ç±»å‹"""
        if 'ä¸»é¡µ' in page_name:
            return 'ä¸»é¡µé¢'
        elif 'åˆ—è¡¨' in page_name or 'ç›®å½•' in page_name:
            return 'åˆ—è¡¨é¡µ'
        elif 'è¯¦æƒ…' in page_name or 'è¯¦ç»†' in page_name:
            return 'è¯¦æƒ…é¡µ'
        else:
            return 'åŠŸèƒ½é¡µ'
    
    def save_results(self):
        """ä¿å­˜çˆ¬å–ç»“æœ"""
        # ä¿å­˜å®Œæ•´çš„JSONæ•°æ®
        json_path = os.path.join(
            CrawlerConfig.OUTPUT_DIR, 
            CrawlerConfig.get_timestamp_filename("crawl_results", ".json")
        )
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(self.crawl_data, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜ç®€åŒ–çš„æŠ¥å‘Š
        report_path = os.path.join(
            CrawlerConfig.OUTPUT_DIR, 
            CrawlerConfig.get_timestamp_filename("crawl_report", ".txt")
        )
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(self._generate_text_report())
        
        print(f"ğŸ’¾ çˆ¬å–ç»“æœå·²ä¿å­˜:")
        print(f"   ğŸ“„ å®Œæ•´æ•°æ®: {json_path}")
        print(f"   ğŸ“‹ æ–‡æœ¬æŠ¥å‘Š: {report_path}")
        
        return json_path, report_path
    
    def _generate_text_report(self):
        """ç”Ÿæˆæ–‡æœ¬æ ¼å¼çš„æŠ¥å‘Š"""
        report = []
        report.append("=" * 60)
        report.append("å¾®ä¿¡å°ç¨‹åºçˆ¬å–æŠ¥å‘Š")
        report.append("=" * 60)
        
        info = self.crawl_data['crawl_info']
        report.append(f"åº”ç”¨åç§°: {info['app_name']}")
        report.append(f"çˆ¬å–æ—¶é—´: {info['start_time']}")
        report.append(f"æ€»é¡µé¢æ•°: {info['total_pages']}")
        report.append(f"æ€»æŒ‰é’®æ•°: {info['total_buttons']}")
        report.append(f"çˆ¬å–è€—æ—¶: {info['crawl_duration']}ç§’")
        report.append("")
        
        # åŠŸèƒ½æ€»ç»“
        summary = self.crawl_data['feature_summary']
        report.append("åŠŸèƒ½æ€»ç»“:")
        report.append(f"  å‘ç°åŠŸèƒ½ç±»å‹: {summary['feature_count']}ç§")
        for func_type, count in summary['feature_categories'].items():
            report.append(f"    - {func_type}: {count}ä¸ª")
        report.append("")
        
        # é¡µé¢è¯¦æƒ…
        report.append("é¡µé¢è¯¦æƒ…:")
        for page in self.crawl_data['pages']:
            report.append(f"  ğŸ“„ {page['page_name']}")
            features = page['extracted_features']
            report.append(f"    - æ–‡æœ¬å…ƒç´ : {len(features['text_elements'])}ä¸ª")
            report.append(f"    - æŒ‰é’®: {len(features['buttons'])}ä¸ª")
            report.append(f"    - å›¾æ ‡: {len(features['icons'])}ä¸ª")
            report.append(f"    - åŠŸèƒ½: {len(features['functionality'])}ä¸ª")
            report.append("")
        
        return "\n".join(report)
    
    def get_crawl_stats(self):
        """è·å–çˆ¬å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_pages': len(self.crawl_data['pages']),
            'total_buttons': len(self.visited_buttons),
            'duration': round(time.time() - self.start_time, 2)
        } 